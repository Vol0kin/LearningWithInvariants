@Article{Vapnik2019,
author={Vapnik, Vladimir
and Izmailov, Rauf},
title={Rethinking statistical learning theory: learning using statistical invariants},
journal={Machine Learning},
year={2019},
month={Mar},
day={01},
volume={108},
number={3},
pages={381-423},
abstract={This paper introduces a new learning paradigm, called Learning Using Statistical Invariants (LUSI), which is different from the classical one. In a classical paradigm, the learning machine constructs a classification rule that minimizes the probability of expected error; it is data-driven model of learning. In the LUSI paradigm, in order to construct the desired classification function, a learning machine computes statistical invariants that are specific for the problem, and then minimizes the expected error in a way that preserves these invariants; it is thus both data- and invariant-driven learning. From a mathematical point of view, methods of the classical paradigm employ mechanisms of strong convergence of approximations to the desired function, whereas methods of the new paradigm employ both strong and weak convergence mechanisms. This can significantly increase the rate of convergence.},
issn={1573-0565},
doi={10.1007/s10994-018-5742-0},
url={https://doi.org/10.1007/s10994-018-5742-0}
}

@article{Vapnik2015,
author = {Vapnik, Vladimir and Izmailov, Rauf},
title = {V-Matrix Method of Solving Statistical Inference Problems},
year = {2015},
issue_date = {January 2015},
publisher = {JMLR.org},
volume = {16},
number = {1},
issn = {1532-4435},
abstract = {This paper presents direct settings and rigorous solutions of the main Statistical Inference problems. It shows that rigorous solutions require solving multidimensional Fredholm integral equations of the first kind in the situation where not only the right-hand side of the equation is an approximation, but the operator in the equation is also defined approximately. Using Stefanuyk-Vapnik theory for solving such ill-posed operator equations, constructive methods of empirical inference are introduced. These methods are based on a new concept called V-matrix. This matrix captures geometric properties of the observation data that are ignored by classical statistical methods.},
journal = {J. Mach. Learn. Res.},
month = {jan},
pages = {1683â€“1730},
numpages = {48},
keywords = {regression, data adaptation, conditional probability, reproducing kernel Hilbert space, function estimation, conditional density, mutual information, interpolation function, support vector machines, density ratio, data balancing, ill-posed problem}
}