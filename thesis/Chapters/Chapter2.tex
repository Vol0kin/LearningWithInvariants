% Chapter Template

\newcommand{\Tau}{\mathcal{T}}
\newcommand{\norm}[1]{\lVert #1 \rVert}
\newcommand{\innerprod}[1]{\left< #1 \right>}
\newcommand{\set}[1]{\lbrace #1 \rbrace}

\chapter{Learning using statistical invariants} % Main chapter title
\label{Chapter2}

Given that this work intends to explore the applications of the invariants in the learning
process, we first need to introduce the background work that proposed this new learning
paradigm, which is called LUSI (Learning Using Statistical Invariants).

This chapter intends to provide the necessary background to understand the basis of this work
and an overview of the most relevant aspects of the original paper that presented the LUSI paradigm,
which was proposed by \cite{Vapnik2019}. For further information and more details, please
refer to the original paper.

\section{Weak convergence and the LUSI paradigm}

Supervised machine learning algorithms try to find the best estimate of some conditional probability
function $P(y = 1 | x)$, i.e., given a data point $x$, we want to compute the probability that this
point belongs to a particular class.

Classical methods do this by using the strong mode of convergence in the Hilbert space. However,
in the LUSI paradigm this estimation is obtained using the weak mode of convergence. Hence, it is
important to understand the difference between this two modes of convergence and what role
the weak mode of convergence plays in the LUSI paradigm.

\subsection{Strong and weak modes of convergence}

In a Hilbert space, the relationships between two functions $f_1(x)$ and $f_2(x)$ have two
numerical properties:

\begin{enumerate}
    \item The distance between functions
    
    \[
        \rho (f_1, f_2) = \norm{f_1(x) - f_2(x)}
    \]
    
    that is defined by the metric of the $L_2$ space and
    
    \item The inner product between functions
    
    \[
        R(f_1, f_2) = \innerprod{f_1(x), f_2(x)}
    \]
    
    that has to satisfy the corresponding requirements.
\end{enumerate}

These two properties imply two different modes of convergence: a strong one and a weak one. Classical
learning paradigms rely on the strong convergence mode (convergence in metrics), trying to find a
sequence of functions $\set{P_l(y=1 | x)}$ such that

\[
    \lim_{l \to \infty} \norm{P_l(y=1 | x) - P(y=1 | x)} = 0\quad \forall x
\]

The weak mode of convergence (convergence in inner products) is given by

\[
    \lim_{l \to \infty} \innerprod{P_l(y=1 | x) - P(y=1 | x), \psi(x)} = 0\quad \forall \psi(x) \in L_2
\]

Note that this mode of convergence has to take place for \emph{all} functions in the Hilbert space $L_2$.

It is known that the strong mode of convergence implies the weak one, although generally speaking, the
reverse is not true.

\subsection{The LUSI paradigm}

Opposite to the classical learning paradigms, LUSI is based on the weak mode of convergence. It replaces
the infinite set of functions with a set of functions $\mathcal{P} = \set{\psi_1(x), \dots, \psi_m(x)}$
called predicates, which describe some important properties of the desired conditional probability function and
restrict the scope of weak convergence only to the set of functions $\mathcal{P}$. These properties are
called invariants, and can be expressed as the following equalities:

\[
    \int \psi_s P(y=1 | x)dP(x) = \int \psi_s P(y=1, x) = a_s,\quad s = 1, \dots, m
\]

where $a_s$ is the expected value of the predicate $\psi_s(x)$ with respect to measure
$P(y=1, x)$. These values are unknown but can be estimated using the training data
$\set{(x_i, y_i),\ i = 1, \dots, l}$. Therefore, the previous expression can be rewritten
as follows:

\begin{equation}
    \label{eq:invariant_approximation}
    \frac{1}{l} \sum_{i=1}^l \psi_s(x_i)P_l(y=1 | x_i) \approx a_s \approx \frac{1}{l} \sum_{i=1}^l y_i \psi_s(x_i),\quad
    s = 1, \dots, m
\end{equation}

Simply put, the general idea of the LUSI paradigm is to find an approximation $P_l(y=1|x)$ of the
real conditional probability function in the subset of functions that preserve the invariants
associated to the set of predicates $\mathcal{P}$, reducing effectively the set of candidate functions
to those that satisfy \eqref{eq:invariant_approximation}.

\subsection{Predicate selection}

In order to find this approximation of the conditional probability function, there must exist
some kind of mechanism that allows us to determine which invariants should be used. Luckily,
the authors propose a very simple way to sequentially selecting invariants. Given an approximation
$P_l^m(y=1|x)$ using $m$ invariants and a new predicate $\psi_{m+1}$ which we would to know whether
it should be considered or not. We can compute the following value before adding it:

\begin{equation}
    \label{eq:predicate_selection}
    \Tau = \frac{\left| \sum_{i=1}^l \psi_{m+1}(x_i) P^m_l(y = 1 | x_i) - \sum_{i=1}^l y_i \psi_{m+1}(x_i) \right|}{\sum_{i=1}^l y_i \psi_{m+1}(x_i)}
\end{equation}

If $\Tau \geq \delta$ for some small threshold $\delta$, the new invariant defined by predicate $\psi_{m+1}$
is considered. Otherwise, the expression \eqref{eq:invariant_approximation} is treated as an equality
and the invariant is not considered in the approximation.


\section{Statistical invariants}

A \emph{statistical invariant} is a specific realization of a predicate with statistical meaning.
This means that it captures some sort of statistical information of the data that has to be
conserved when selecting the best approximation of the conditional probability function.

There are different types of statistical invariants, each one of them
providing different information about the data. In this case, the authors have considered
two in particular: the zeroth order and first order moments of the conditional probability
function $P(y=1|x)$. We will briefly discuss each one of them and see what kind of information
they provide.

\subsection{Zeroth order invariant}

Suppose that we are given a binary classification problem, in which the positive instances
are labeled as 1 and the negative ones as 0. The zeroth order invariant would give us information
about the ratio of elements of the positive class. It is defined as follows:

\[
    \psi_0(x) = 1
\]

The logic behind it is the following: the predicate is applied to each single sample in the dataset,
which will yield the vector $(1, \dots, 1) \in \mathbb{R}^l $, where $l$ is the number of samples. Taking into account
expression \eqref{eq:invariant_approximation}, we can see that each element of this vector is multiplied
by the predicted labels (left side) and the true labels (right side). These values are summed and then divided
by $l$, which gives us the proportion of positive predicted elements on the left side and the proportion
of true positive elements on the right side. Notice that the invariant is only taken into account for those
elements whose predicted or true label is positive. Thus, the negative samples are not considered.

\subsection{First order invariant}

Suppose the same case scenario as in the previous subsection. If we apply the first order invariant to
a dataset, we would get the mean or centroid of the positive class. Its mathematical expression is:

\[
    \psi_1(x) = x
\]

Same as before, when this predicate is applied to the dataset it will generate the vector
$(x_1, \dots, x_l) \in \mathbb{R}^l$. Following expression \eqref{eq:invariant_approximation} again,
only the positive true or predicted elements will be considered. Therefore, their values will be summed and
then averaged, yielding indeed the centroid of the positive class (both for the predicted and true labels).

\section{Solving the learning problem}



\section{Overview of the LUSI algorithm}

\section{Main results}

La seleccion del invariante es problem dependent y es un "black-art".
